# ðŸ§  LFMC: Enhancing LLMs' Logical Reasoning through Mistake Correction

## Description

Large Language Models (LLMs) are widely used for text generation but still exhibit deficiencies in **logical reasoning**, especially their **inability to self-improve through reflection on errors**.

This project introduces **LFMC**, a fine-tuning framework designed to enhance LLMsâ€™ reasoning capabilities by learning from **mistake correction**:

- Automatically detects and corrects reasoning errors using GPT-4.
- Constructs the **LOCD (Logical Correction Dataset)**.
- Fine-tunes models with **QLoRA** to efficiently improve reasoning consistency and logical accuracy.

Experiments across multiple benchmarks (FOLIO, ReClor, LogiQA, LFUD, etc.) show that LFMC-fine-tuned models outperform standard instruction-tuned baselines, confirming that **reasoning through correction** leads to better logical generalization.

---

## Methodology
<div align="center">
  <img 
    src="https://github.com/user-attachments/assets/091b6b77-29f6-449e-a352-bb1134f91e3b"
    alt="LFMC_architecture_en_fold"
    width="80%"
  />
</div>

1. Collect logical errors by sampling model outputs and filtering inconsistent reasoning.
2. Use GPT-4 to correct reasoning chains while keeping semantic intent.
3. Construct LOCD combining original & corrected chains for supervised fine-tuning.
4. Fine-tune with QLoRA and low-rank adapters.
5. Evaluate on multiple reasoning benchmarks using accuracy.

---

## Project structure

```
LFMC/
â”œâ”€â”€ data/                # Datasets (original logical questions & logical correction reasoning(LOCD) )
â”œâ”€â”€ root/                # Model weights and configurations
â”œâ”€â”€ config/              # QLoRA fine-tuning scripts
â”œâ”€â”€ logic_llm/           
â”‚   â”œâ”€â”€ wrong_reasoning_collection/    # Collect erroneous reasoning
â”‚   â”œâ”€â”€ evaluate/                      # Evaluation scripts
â”‚   â”œâ”€â”€ results/                       # Save test results
â”œâ”€â”€ gpt4_correct/        # GPT-4 correction pipeline
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md
```

---

## Dataset Information of LOCD

**Dataset name:** LOCD (Logical Correction Dataset)
- **Source:** Collected from reasoning errors generated by LLaMA3-8B, then corrected by GPT-4.
- **Format:** JSONL (each sample includes question, reasoning, error type, and corrected reasoning).
- **Origin datasets:** FOLIO, ReClor, LogiQA_v2, logiqa-zh.
- **Url**: https://github.com/Zhuxingxing45/LFMC/tree/main/data/LOCD

---

## Code Information

**Algorithms implemented:**

1. Error Collection â€“ generate reasoning chains and collect those with logical mistakes(`logic_llm/wrong_reasoning_colloction/basemodel`).
2. Error Correction â€“ use GPT-4 to correct flawed reasoning paths (`gpt4_correct/logic_correction_v2.py`).
3. Fine-tuning â€“ QLoRA-based fine-tuning (configs in `config/`).
4. Evaluation â€“ benchmark evaluation (`logic_llm/evaluate/`).

---

## Requirements

- **GPU:** NVIDIA GeForce RTX 4090 (recommended)
- **Python:** >= 3.10
- **CUDA:** >= 12.1
- **Core dependencies:** see `requirements.txt`

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## Reproduction Script

Several helper shell scripts are provided under the scripts/ directory to automate the full experimental workflow:

generate_LOCD.sh â€” Generates logical correction data (LOCD) using GPT-4.

fine-tune.sh â€” Fine-tunes the base model on the generated LOCD dataset.

run_evaluation.sh â€” Evaluates the fine-tuned model and aggregates results.

  *Note: These scripts assume that configuration files and data paths are properly set, valid API keys are available, and sufficient GPU resources are provided.*

---

## Usage Instructions

### 1. Clone the repository

```bash
git clone git@github.com:Zhuxingxing45/LFMC.git
cd LFMC
```

### 2. Create a virtual environment (recommended)

```bash
conda create -n lfmc python=3.10
conda activate lfmc
pip install -r requirements.txt
```

### 3. Download Base Model
Before running fine-tuning, download the base model from Hugging Face Hub using the huggingface-cli.
This step ensures that the pretrained model weights are locally available for QLoRA fine-tuning.
```bash
huggingface-cli login
export HF_TOKEN=<your_huggingface_token>

huggingface-cli download --resume-download meta-llama/Llama-3.1-8B-Instruct \
    --local-dir ./meta-llama/Llama-3.1-8B-Instruct

huggingface-cli download --resume-download internlm/internlm-chat-7b \
    --local-dir ./internlm/internlm-chat-7b

huggingface-cli download --resume-download Qwen/Qwen3-8B \
    --local-dir ./Qwen/Qwen3-8B

huggingface-cli download --resume-download Qwen/Qwen3-4B \
    --local-dir ./Qwen/Qwen3-4B

```

### 3. Generate corrected reasoning data
```bash
cd scripts
chmod +x generate_LOCD.sh
export OPENAI_API_KEY="sk-xxxx"
./generate_LOCD.sh
```

### 4. Fine-tune the model
```bash
chmod +x scripts/fine-tune.sh
bash  scripts/fine-tune.sh
```

Example:
```bash
xtuner train configs/llama/llama3_correction/llama3_8b_instruct_qlora_logic_correct_ez.py     --work-dir root/llama3-8b/lfmc_logic_correct/
```

Convert checkpoint:

```bash
xtuner convert pth_to_hf <config_path> <checkpoint_path> <adapter_output_path>
```

Merged
```bash
xtuner convert merge \
    <base_model_path> \
    <adapter_output_path> \
    <merged_model_path>
```


### 5. Evaluate

```bash
bash scripts/run_evaluation.sh /path/to/merged_model
```
**Benchmark result in paper**
<div align="center">
  <img 
    src="[https://github.com/user-attachments/assets/091b6b77-29f6-449e-a352-bb1134f91e3b](https://github.com/Zhuxingxing45/LFMC/blob/main/images/benchmark%20results%20in%20paper.png)"
    alt="benchmark_result"
    width="80%"
  />
</div>

---


## Citations

If you use LFMC or LOCD, please cite:

```
@article{zhu2025lfmc,
  title={LFMC: Enhancing Large Language Models' Logical Reasoning through Mistake Correction},
  author={Zhu, Xingxing and Huang, Xiaoxi},
  year={2025},
  journal={Under Review}
}
```

---

## License

This project is licensed under the MIT License. See `LICENSE` for details.

---

## Contribution Guidelines

1. Fork the repo
2. Create a branch `feature/...`
3. Open a PR with description and tests
4. Keep code style consistent and document changes

---
