# ğŸ§  LFMC: Enhancing LLMs' Logical Reasoning through Mistake Correction

## ğŸ“– é¡¹ç›®ç®€ä»‹

åœ¨è¿‘å¹´æ¥ï¼Œ**å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰** ç”±äºå…¶å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›è€Œè¢«å¹¿æ³›åº”ç”¨ã€‚ä½†å®ƒä»¬åœ¨é€»è¾‘æ¨ç†ä¸­ä»å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯**ç¼ºä¹åƒäººç±»ä¸€æ ·é€šè¿‡é”™è¯¯åæ€æ¥æå‡æ¨ç†èƒ½åŠ›**ã€‚

æœ¬é¡¹ç›®æå‡º **LFMC (Logic Fine-tuning with Mistake Correction)** æ–¹æ³•ï¼š

* ä½¿ç”¨ GPT-4 è‡ªåŠ¨ä¿®æ­£åŒ…å«é€»è¾‘é”™è¯¯çš„æ¨ç†è·¯å¾„
* æ„å»º **LOCD (Logical Error Correction Dataset)** æ•°æ®é›†
* ä½¿ç”¨LOCDï¼Œé€šè¿‡ **QLoRA** é«˜æ•ˆå¾®è°ƒæå‡å¤šç§å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›

å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨ LOCD å¾®è°ƒåçš„æ¨¡å‹åœ¨å››ä¸ªé€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šå‡è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº† LLMs èƒ½å¤Ÿé€šè¿‡é”™è¯¯ä¿®æ­£å­¦ä¹ æ›´ç¨³å¥çš„é€»è¾‘æ¨ç†ã€‚

---

## ğŸ“‚ Project Structure

```
LFMC/
â”œâ”€â”€ data/                # Datasets (original logical questions & corrected reasoning paths)
â”œâ”€â”€ root/                # Model weights and configurations
â”œâ”€â”€ config/              # QLoRA fine-tuning scripts
â”œâ”€â”€ results/             # Experimental results
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ“¦ Installation & Usage

### Environment

* GPU: NVIDIA GeForce RTX 4090
* Python >= 3.10
* CUDA >= 12.1 
* Dependencies: Listed in `requirements.txt`

### Installation

```bash
# Clone the repository:
git clone git@github.com:Zhuxingxing45/LFMC.git
cd LFMC

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
conda create -n yourenv python=3.10
conda activate yourenv
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install -r requirements.txt
```

### Usage
### Training
This section describes how to fine-tune a single model  with the training configuration.

### 1. Training a Single Model
All training configurations are located in the `configs` directory.  
For example, to train the LLaMA3-8B model with LOCD data:
```bash
# Train the model
xtuner train configs/llama/llama3_correction/llama3_8b_instruct_qlora_logic_correct_ez.py \
    --work-dir root/llama3-8b/llama3_logic_lfud/llama3_logic_original_pth
```

Convert checkpoint to HuggingFace adapter:
```bash
xtuner convert pth_to_hf <config_path> <checkpoint_path> <adapter_output_path>
```


Merge with base model (optional):

```bash
export MKL_SERVICE_FORCE_INTEL=1
xtuner convert merge <base_model_path> <adapter_path> <merged_model_path>
```

---

## **Evaluation**

Evaluate the fine-tuned model:

```bash
python logic_llm/qwen3/evaluate.py \
    --model_path <merged_model_path> \
    --output_path <generate_data_path> \
    --result_path <accuracy_json_path>
```

---

## **Data**

* LOCD dataset located in `./data/LOCD` (training/validation/test splits included)
* External datasets used: 
    * FOLIO: [https://github.com/Yale-LILY/FOLIO](https://github.com/Yale-LILY/FOLIO)
  * ReClor: [https://whyu.me/reclor/](https://whyu.me/reclor/)
  * LogiQA_v2: [https://github.com/csitfun/LogiQA2.0](https://github.com/csitfun/LogiQA2.0)
  * logiqa-zh: [https://doi.org/10.48550/arXiv.2007.08124](https://doi.org/10.48550/arXiv.2007.08124)
  * LogiCoT: [https://github.com/csitfun/LogiCoT](https://github.com/csitfun/LogiCoT)
  * LFUD: [https://github.com/YandaGo/LFUD](https://github.com/YandaGo/LFUD)
---

## ğŸš€ LOCDæ•°æ®é›†æ„å»º

### 1. æ”¶é›†åœ¨åŸå§‹æ•°æ®é›†ä¸Šç”Ÿæˆçš„é”™è¯¯æ¨ç†æ•°æ®


* ğŸ” **é€»è¾‘é”™è¯¯ä¿®æ­£**ï¼šåˆ©ç”¨ GPT-4 ç”Ÿæˆæ­£ç¡®çš„æ¨ç†è·¯å¾„
* 
* ğŸ“Š **LOCD æ•°æ®é›†æ„å»º**ï¼šåŸå§‹é€»è¾‘é—®é¢˜ + GPT-4 ä¿®æ­£è¾“å‡º
* âš¡ **é«˜æ•ˆå¾®è°ƒ**ï¼šé€šè¿‡ QLoRA å¯¹ LLaMA3-8B è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ
* ğŸ§ª **å®éªŒéªŒè¯**ï¼šåœ¨å››ä¸ªé€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡æ€§èƒ½








